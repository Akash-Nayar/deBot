{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib notebook\n",
    "import pandas as pd\n",
    "import mygrad as mg\n",
    "import numpy as np\n",
    "import re\n",
    "from mynn.layers.dense import dense\n",
    "from mynn.initializers.glorot_normal import glorot_normal\n",
    "from mynn.optimizers.adam import Adam\n",
    "from mygrad.nnet.losses import softmax_crossentropy\n",
    "from gensim.models.keyedvectors import KeyedVectors\n",
    "from noggin import create_plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "glove = KeyedVectors.load_word2vec_format(\"glove.6B.50d.txt.w2v\", binary=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\"\"\"\n",
    "Running this file trains an argument quality model and saves it to a file ArgumentQualityModel.npy.\n",
    "Do not run this every time you want to test the model on your data.\n",
    "Only run this once at the beginning to create the ArgumentQuality.npy file\n",
    "    or to retrain the model.\n",
    "This file should take a few minutes to run as it trains over 10 epochs on thousands of data items.\n",
    "\"\"\"\n",
    "\n",
    "# Loads glove, which contains english words and their embeddings into 50-dimensional vectors\n",
    "\n",
    "\n",
    "\n",
    "def l2loss(pred, actual):  # L2 loss function (mean square distance)\n",
    "    \"\"\"\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    pred: Union[mygrad.Tensor, numpy.ndarray]\n",
    "        A tensor or numpy array containing the model's predicted values\n",
    "    actual: Union[mygrad.Tensor, numpy.ndarray]\n",
    "        A tensor or numpy array containing the actual values\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    mg.Tensor\n",
    "        A tensor containing the mean square distance between the prediction and actual values.\n",
    "    \"\"\"\n",
    "    return mg.mean(mg.square(pred - actual))\n",
    "class RNN:  # The RNN class, which passes the data through a gated recurrent unit to convert each sentence into an array\n",
    "    def __init__(self, dim_input, dim_recurrent, dim_output):\n",
    "        \"\"\" Initializes all layers needed for RNN\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        dim_input: int\n",
    "            Dimensionality of data passed to RNN (C)\n",
    "\n",
    "        dim_recurrent: int\n",
    "            Dimensionality of hidden state in RNN (D)\n",
    "\n",
    "        dim_output: int\n",
    "            Dimensionality of output of RNN (K)\n",
    "        \"\"\"\n",
    "        self.fc_x2h = dense(dim_input, dim_recurrent, weight_initializer=glorot_normal)\n",
    "        self.fc_h2h = dense(\n",
    "            dim_recurrent, dim_recurrent, weight_initializer=glorot_normal, bias=False\n",
    "        )\n",
    "        self.fc_h2y = dense(dim_recurrent, dim_output, weight_initializer=glorot_normal)\n",
    "        self.Uz = mg.Tensor(\n",
    "            np.random.randn(dim_input * dim_recurrent).reshape(dim_input, dim_recurrent)\n",
    "        )\n",
    "        self.Wz = mg.Tensor(\n",
    "            np.random.randn(dim_recurrent * dim_recurrent).reshape(\n",
    "                dim_recurrent, dim_recurrent\n",
    "            )\n",
    "        )\n",
    "        self.bz = mg.Tensor(np.random.randn(dim_recurrent))\n",
    "        self.Ur = mg.Tensor(\n",
    "            np.random.randn(dim_input * dim_recurrent).reshape(dim_input, dim_recurrent)\n",
    "        )\n",
    "        self.Wr = mg.Tensor(\n",
    "            np.random.randn(dim_recurrent * dim_recurrent).reshape(\n",
    "                dim_recurrent, dim_recurrent\n",
    "            )\n",
    "        )\n",
    "        self.br = mg.Tensor(np.random.randn(dim_recurrent))\n",
    "        self.Uh = mg.Tensor(\n",
    "            np.random.randn(dim_input * dim_recurrent).reshape(dim_input, dim_recurrent)\n",
    "        )\n",
    "        self.Wh = mg.Tensor(\n",
    "            np.random.randn(dim_recurrent * dim_recurrent).reshape(\n",
    "                dim_recurrent, dim_recurrent\n",
    "            )\n",
    "        )\n",
    "        self.bh = mg.Tensor(np.random.randn(dim_recurrent))\n",
    "\n",
    "    def __call__(self, x):\n",
    "        \"\"\" Performs the full forward pass for the RNN.\n",
    "\n",
    "        Note that we only care about the last y - the final classification scores for the full sequence\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        x: Union[numpy.ndarray, mygrad.Tensor], shape=(T, C)\n",
    "            The one-hot encodings for the sequence\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        mygrad.Tensor, shape=(1, K)\n",
    "            The final classification of the sequence\n",
    "        \"\"\"\n",
    "\n",
    "        h = mg.nnet.gru(\n",
    "            x,\n",
    "            self.Uz,\n",
    "            self.Wz,\n",
    "            self.bz,\n",
    "            self.Ur,\n",
    "            self.Wr,\n",
    "            self.br,\n",
    "            self.Uh,\n",
    "            self.Wh,\n",
    "            self.bh,\n",
    "        )\n",
    "        return self.fc_h2y(h[-1])\n",
    "\n",
    "    @property\n",
    "    def parameters(self):\n",
    "        \"\"\" A convenience function for getting all the parameters of our model.\n",
    "\n",
    "        This can be accessed as an attribute, via `model.parameters`\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        Tuple[Tensor, ...]\n",
    "            A tuple containing all of the learnable parameters for our model\n",
    "        \"\"\"\n",
    "        return self.fc_x2h.parameters + self.fc_h2h.parameters + self.fc_h2y.parameters + (self.Uz, self.Wz, self.bz, self.Ur, self.Wr, self.br, self.Uh, self.Wh, self.bh)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def round20(n):\n",
    "    return round(20*n)/20\n",
    "\n",
    "def get_arr(n):\n",
    "    z= np.zeros(21, dtype=int)\n",
    "    z[int(20*n)] = int(1)\n",
    "    return z\n",
    "# Reads the csv file containing the train data\n",
    "panda = pd.read_csv(\"train.csv\")\n",
    "nums = np.linspace(0,1,21)\n",
    "print(nums)\n",
    "# Creates arrays containing the evidence given that both stances are the same.\n",
    "stance1 = np.array(panda[\"evidence_1_stance\"])\n",
    "stance2 = np.array(panda[\"evidence_2_stance\"])\n",
    "evidence_1 = [\n",
    "    panda[\"evidence_1\"][i] for i in range(len(stance1)) if stance1[i] == stance2[i]\n",
    "]\n",
    "evidence_2 = [\n",
    "    panda[\"evidence_2\"][i] for i in range(len(stance1)) if stance1[i] == stance2[i]\n",
    "]\n",
    "\n",
    "# Creates arrays containing the scores of the evidence given that both stances are the same.\n",
    "y_train1 = [\n",
    "    int(20*round20(panda[\"evidence_1_detection_score\"][i]))\n",
    "    for i in range(len(stance1))\n",
    "    if stance1[i] == stance2[i]\n",
    "]\n",
    "y_train2 = [\n",
    "    int(20*round20(panda[\"evidence_2_detection_score\"][i]))\n",
    "    for i in range(len(stance1))\n",
    "    if stance1[i] == stance2[i]\n",
    "]\n",
    "\n",
    "# Takes in the text and converts it into an array of sentences.\n",
    "x_train1 = []\n",
    "indices_1 = []\n",
    "for index, i in enumerate(evidence_1):\n",
    "\n",
    "    i = i.lower().replace(\"[ref]\", \"\")\n",
    "    i = \"\".join(c for c in i if c.isdigit() or c.isalpha() or c == \" \")\n",
    "    i = re.sub(r\" \\W+\", \" \", i)\n",
    "    i = i.split()\n",
    "    row = []\n",
    "    for word in i:\n",
    "        try:\n",
    "            row.append(glove[word])\n",
    "        except:\n",
    "            continue\n",
    "    x_train1.append(row)\n",
    "\n",
    "# Makes all sentence arrays the same shape by adding arrays of zeros to the end.\n",
    "for i in x_train1:\n",
    "    for j in range(len(i), 78):\n",
    "        i.append(np.zeros(50))\n",
    "\n",
    "# Repeats the process above for the 2nd half of the train data\n",
    "x_train2 = []\n",
    "indices_2 = []\n",
    "for index, i in enumerate(evidence_2):\n",
    "\n",
    "    i = i.lower().replace(\"[ref]\", \"\")\n",
    "    i = \"\".join(c for c in i if c.isdigit() or c.isalpha() or c == \" \")\n",
    "    i = re.sub(r\" \\W+\", \" \", i)\n",
    "    i = i.split()\n",
    "    row = []\n",
    "    for word in i:\n",
    "        try:\n",
    "            row.append(glove[word])\n",
    "        except:\n",
    "            continue\n",
    "    x_train2.append(row)\n",
    "for i in x_train2:\n",
    "    for j in range(len(i), 78):\n",
    "        i.append(np.zeros(50))\n",
    "        \n",
    "#SECOND HALF\n",
    "panda2 = pd.read_csv(\"test.csv\")\n",
    "nums = np.linspace(0,1,21)\n",
    "print(nums)\n",
    "# Creates arrays containing the evidence given that both stances are the same.\n",
    "stance3 = np.array(panda2[\"evidence_1_stance\"])\n",
    "stance4 = np.array(panda2[\"evidence_2_stance\"])\n",
    "evidence_3 = [\n",
    "    panda2[\"evidence_1\"][i] for i in range(len(stance3)) if stance3[i] == stance4[i]\n",
    "]\n",
    "evidence_4 = [\n",
    "    panda2[\"evidence_2\"][i] for i in range(len(stance3)) if stance3[i] == stance4[i]\n",
    "]\n",
    "\n",
    "# Creates arrays containing the scores of the evidence given that both stances are the same.\n",
    "y_train3 = [\n",
    "    int(20*round20(panda2[\"evidence_1_detection_score\"][i]))\n",
    "    for i in range(len(stance3))\n",
    "    if stance3[i] == stance4[i]\n",
    "]\n",
    "y_train4 = [\n",
    "    int(20*round20(panda2[\"evidence_2_detection_score\"][i]))\n",
    "    for i in range(len(stance4))\n",
    "    if stance3[i] == stance4[i]\n",
    "]\n",
    "\n",
    "# Takes in the text and converts it into an array of sentences.\n",
    "x_train3 = []\n",
    "indices_1 = []\n",
    "for index, i in enumerate(evidence_3):\n",
    "\n",
    "    i = i.lower().replace(\"[ref]\", \"\")\n",
    "    i = \"\".join(c for c in i if c.isdigit() or c.isalpha() or c == \" \")\n",
    "    i = re.sub(r\" \\W+\", \" \", i)\n",
    "    i = i.split()\n",
    "    row = []\n",
    "    for word in i:\n",
    "        try:\n",
    "            row.append(glove[word])\n",
    "        except:\n",
    "            continue\n",
    "    x_train3.append(row)\n",
    "\n",
    "# Makes all sentence arrays the same shape by adding arrays of zeros to the end.\n",
    "for i in x_train3:\n",
    "    for j in range(len(i), 78):\n",
    "        i.append(np.zeros(50))\n",
    "\n",
    "# Repeats the process above for the 2nd half of the train data\n",
    "x_train4 = []\n",
    "indices_2 = []\n",
    "for index, i in enumerate(evidence_4):\n",
    "\n",
    "    i = i.lower().replace(\"[ref]\", \"\")\n",
    "    i = \"\".join(c for c in i if c.isdigit() or c.isalpha() or c == \" \")\n",
    "    i = re.sub(r\" \\W+\", \" \", i)\n",
    "    i = i.split()\n",
    "    row = []\n",
    "    for word in i:\n",
    "        try:\n",
    "            row.append(glove[word])\n",
    "        except:\n",
    "            continue\n",
    "    x_train4.append(row)\n",
    "for i in x_train4:\n",
    "    for j in range(len(i), 78):\n",
    "        i.append(np.zeros(50))\n",
    "# Concatenates the 2 sets of train data\n",
    "xtrain = np.array(x_train1 + x_train2 + x_train3 + x_train4)\n",
    "\n",
    "ytrain = np.array(y_train1 + y_train2 + y_train3 + y_train4)\n",
    "\n",
    "print(xtrain.shape, ytrain.shape)\n",
    "# Initializes the optimizer and the model with parameters.\n",
    "dim_input = 50\n",
    "dim_recurrent = 10\n",
    "dim_output = 21\n",
    "rnn = RNN(dim_input, dim_recurrent, dim_output)\n",
    "optimizer = Adam(rnn.parameters)\n",
    "\n",
    "\n",
    "plotter, fig, ax = create_plot(metrics=[\"loss\"])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "batch_size = 20\n",
    "\n",
    "# Trains the model over 10 epochs.\n",
    "for epoch_cnt in range(50):\n",
    "    idxs = np.arange(len(xtrain))\n",
    "    np.random.shuffle(idxs)\n",
    "    print(\"training epoch number \", epoch_cnt)\n",
    "\n",
    "    for batch_cnt in range(0, len(xtrain) // batch_size):\n",
    "        batch_indices = idxs[batch_cnt * batch_size : (batch_cnt + 1) * batch_size]\n",
    "        \n",
    "        old = xtrain[batch_indices]\n",
    "        batch = np.ascontiguousarray(np.swapaxes(old, 0, 1))\n",
    "        prediction = rnn(batch)\n",
    "        #print(prediction.shape)\n",
    "        truth = ytrain[batch_indices]\n",
    "        #print(\"pred: \", prediction)\n",
    "        #print(\"truth: \", truth)\n",
    "        loss = softmax_crossentropy(prediction, truth)\n",
    "\n",
    "        loss.backward()\n",
    "\n",
    "        optimizer.step()\n",
    "        loss.null_gradients()\n",
    "\n",
    "        plotter.set_train_batch({\"loss\": loss.item()}, batch_size=batch_size)\n",
    "    plotter.set_train_epoch()\n",
    "\n",
    "\n",
    "diff = 0\n",
    "sum = 0\n",
    "\n",
    "# Tests the model\n",
    "for i in range(len(ytrain)):\n",
    "    old = xtrain[i]\n",
    "    w = np.ascontiguousarray(np.swapaxes(np.array(old).reshape(1, 78, 50), 0, 1))\n",
    "    pred = rnn(w)\n",
    "    true = ytrain[i]\n",
    "    diff += mg.abs(pred - true)\n",
    "    sum += true\n",
    "\n",
    "\n",
    "i = 1\n",
    "old = xtrain[i]\n",
    "\n",
    "w = np.ascontiguousarray(np.swapaxes(np.array(old).reshape(1, 78, 50), 0, 1))\n",
    "pred = rnn(w)\n",
    "true = ytrain[i]\n",
    "\n",
    "# Saves the model as \"ArgumentQualityModel.npy\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#x = xtrain[i]\n",
    "#a = glove[\"hello\"]\n",
    "#w = np.ascontiguousarray(np.swapaxes(np.array(x).reshape(1,78,50),0,1))\n",
    "#print(np.argmax(rnn(w))/20, ytrain[i]/20)\n",
    "sum = 0\n",
    "\n",
    "for i in range(len(ytrain)):\n",
    "    sum+=np.abs((np.argmax(rnn(np.ascontiguousarray(np.swapaxes(np.array(xtrain[i]).reshape(1,78,50),0,1))))/20)-(ytrain[i]/20))\n",
    "print(sum/len(ytrain))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = input(\"What is your argument? \")\n",
    "i = i.lower().replace(\"[ref]\", \"\")\n",
    "i = \"\".join(c for c in i if c.isdigit() or c.isalpha() or c == \" \")\n",
    "i = re.sub(r\" \\W+\", \" \", i)\n",
    "i = i.split()\n",
    "test = []\n",
    "row = []\n",
    "for word in i:\n",
    "    try:\n",
    "        row.append(glove[word])\n",
    "    except:\n",
    "        continue\n",
    "test.append(row)\n",
    "for i in test:\n",
    "    for j in range(len(i), 78):\n",
    "        i.append(np.zeros(50))\n",
    "w = np.ascontiguousarray(np.swapaxes(np.array(test).reshape(1,78,50),0,1))\n",
    "print(np.argmax(rnn(w))/20)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "j = rnn.parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k = RNN(50, 10, 21)\n",
    "k.fc_x2h.weight, k.fc_x2h.bias, k.fc_h2h.weight, k.fc_h2y.weight, k.fc_h2y.bias, k.Uz, k.Wz, k.bz, k.Ur, k.Wr, k.br, k.Uh, k.Wh, k.bh = (\n",
    "    j[0],\n",
    "    j[1],\n",
    "    j[2],\n",
    "    j[3],\n",
    "    j[4],\n",
    "    j[5],\n",
    "    j[6],\n",
    "    j[7],\n",
    "    j[8],\n",
    "    j[9],\n",
    "    j[10],\n",
    "    j[11],\n",
    "    j[12],\n",
    "    j[13],\n",
    ")\n",
    "\n",
    "i = input(\"What is your argument? \")\n",
    "i = i.lower().replace(\"[ref]\", \"\")\n",
    "i = \"\".join(c for c in i if c.isdigit() or c.isalpha() or c == \" \")\n",
    "i = re.sub(r\" \\W+\", \" \", i)\n",
    "i = i.split()\n",
    "test = []\n",
    "row = []\n",
    "for word in i:\n",
    "    try:\n",
    "        row.append(glove[word])\n",
    "    except:\n",
    "        continue\n",
    "test.append(row)\n",
    "for i in test:\n",
    "    for j in range(len(i), 78):\n",
    "        i.append(np.zeros(50))\n",
    "w = np.ascontiguousarray(np.swapaxes(np.array(test).reshape(1,78,50),0,1))\n",
    "print(np.argmax(k(w))/20)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
